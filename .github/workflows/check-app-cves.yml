name: Check App CVEs

on:
  workflow_dispatch:
  schedule:
    - cron: "0 22 * * 0" # Run at 10 PM UTC (12 AM CET) every Sunday

# Set permissions for the GITHUB_TOKEN
permissions:
  contents: write # This allows the workflow to push changes to the repository

jobs:
  check-cves:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests supabase

      - name: Read supported apps
        id: read-apps
        run: |
          # Read the supported_apps.json file
          echo "Reading supported apps from supported_apps.json"

      - name: Check CVEs for apps
        env:
          NVD_API_KEY: ${{ secrets.NVD_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          cat > check_cves.py << 'EOF'
          import os
          import sys
          import requests
          import json
          import time
          import pathlib
          from datetime import datetime, timedelta
          from urllib.parse import quote
          from supabase import create_client, Client

          # Get NVD API key from environment - required
          nvd_api_key = os.environ.get('NVD_API_KEY')

          # Check if API key is available
          if not nvd_api_key:
              print("ERROR: NVD_API_KEY is required but not found in environment variables.")
              print("Please add your NVD API key as a repository secret named NVD_API_KEY.")
              print("Get an API key at: https://nvd.nist.gov/developers/request-an-api-key")
              sys.exit(1)
              
          # Initialize Supabase client
          supabase_url = os.environ.get('SUPABASE_URL')
          supabase_key = os.environ.get('SUPABASE_KEY')

          if not supabase_url or not supabase_key:
              print("ERROR: Supabase credentials are required but not found in environment variables.")
              print("Please add your Supabase URL and service role key as repository secrets.")
              sys.exit(1)
              
          supabase: Client = create_client(supabase_url, supabase_key)
              
          # With API key, rate limits are 50 requests per 30 seconds

          import json

          # Function to get proper app name from app JSON file
          def get_app_display_name(app_key, app_url):
              try:
                  response = requests.get(app_url)
                  if response.status_code == 200:
                      app_data = response.json()
                      # Get the display name from the JSON file
                      display_name = app_data.get('name') or app_data.get('display_name')
                      if display_name:
                          return display_name
                  # If we can't get the display name, format the key as a fallback
                  return ' '.join(word.capitalize() for word in app_key.split('_'))
              except Exception as e:
                  print(f"Error fetching app info for {app_key}: {str(e)}")
                  # Format the key as a fallback
                  return ' '.join(word.capitalize() for word in app_key.split('_'))

          # Create CVE directory if it doesn't exist
          cve_dir = pathlib.Path('CVE')
          cve_dir.mkdir(exist_ok=True)

          # Read the supported apps from the JSON file
          try:
              with open('supported_apps.json', 'r') as f:
                  supported_apps = json.load(f)
              
              print(f"Found {len(supported_apps)} apps in supported_apps.json")
              
              # Process all apps
              app_display_names = []
              app_keys = []
              
              for app_key, app_url in supported_apps.items():
                  display_name = get_app_display_name(app_key, app_url)
                  app_display_names.append(display_name)
                  app_keys.append(app_key)
                  
                  # Add a small delay to avoid rate limiting when fetching app info
                  time.sleep(0.1)
              
              print(f"Processing {len(app_display_names)} apps for CVE checks")
              
          except Exception as e:
              print(f"Error reading supported_apps.json: {str(e)}")
              sys.exit(1)

          # List of apps to check
          apps_to_check = app_display_names

          # Function to get CPE names for an app
          def get_cpe_names(app_name):
              print(f"\n{'=' * 50}")
              print(f"Finding CPE names for {app_name}")
              print(f"{'=' * 50}")
              
              # Normalize app name for search and ensure exact match
              search_term = app_name.strip()
              
              try:
                  # Query the NVD API for CPE names
                  # Construct the URL directly to ensure exact format
                  search_term_encoded = quote(search_term)
                  url = f"https://services.nvd.nist.gov/rest/json/cpes/2.0?keywordSearch={search_term_encoded}&keywordExactMatch"
                  params = {}  # No params as they're included in the URL
                  
                  # Set up headers with API key
                  headers = {'apiKey': nvd_api_key}
                  
                  # Make the request with API key in headers
                  print(f"Querying CPE API for: {search_term}")
                  print(f"URL: {url}")
                  response = requests.get(url, headers=headers)
                  
                  # Check if request was successful
                  if response.status_code != 200:
                      print(f"Error: CPE API request failed with status code {response.status_code}")
                      print(f"Response: {response.text}")
                      return []
                  
                  # Parse the JSON response
                  data = response.json()
                  
                  # Print the structure of the response for debugging
                  print(f"Response structure: {list(data.keys())}")
                  print(f"Total results: {data.get('totalResults', 0)}")
                  
                  # Extract CPEs from the products array
                  products = data.get('products', [])
                  
                  if not products:
                      print(f"No CPE names found for {app_name}.")
                      return []
                  
                  print(f"Found {len(products)} CPE entries in the products array.")
                  
                  # Debug: Print the type of products
                  print(f"Products type: {type(products)}")
                  
                  # If products is a list, print the type of the first few items
                  if isinstance(products, list) and products:
                      print(f"First product type: {type(products[0])}")
                      if len(products) > 1:
                          print(f"Second product type: {type(products[1])}")
                  
                  # Debug: Print the first product to see its structure
                  if products:
                      print(f"First product structure: {list(products[0].keys()) if isinstance(products[0], dict) else 'Not a dict'}")
                  
                  # Process the products based on their structure
                  processed_products = []
                  
                  # Check if products is a list of dictionaries with 'cpe' key
                  if all(isinstance(p, dict) and 'cpe' in p for p in products if isinstance(p, dict)):
                      processed_products = products
                  else:
                      # The API response might have a different structure
                      # Try to extract CPE objects from the response
                      print("Trying alternative product structure extraction...")
                      
                      # Check if the response has numeric indices in the products array
                      # This handles the case where products looks like [0: {cpe: {...}}, 1: {cpe: {...}}]
                      for i in range(len(products)):
                          if i < len(products) and isinstance(products[i], dict) and 'cpe' in products[i]:
                              processed_products.append(products[i])
                  
                  if not processed_products:
                      print(f"No valid CPE entries found for {app_name}.")
                      return []
                  
                  print(f"Processed {len(processed_products)} valid CPE entries.")
                  
                  # Sort by published date (descending) to get the most recent ones
                  def extract_date_for_sorting(product):
                      # Get the created date (which is the published date) from the cpe object
                      cpe_obj = product.get('cpe', {})
                      published_date = cpe_obj.get('created', '')
                      # Parse the date string into a datetime object for sorting
                      try:
                          if published_date:
                              return datetime.strptime(published_date.split('.')[0], "%Y-%m-%dT%H:%M:%S")
                          return datetime.min
                      except Exception as e:
                          print(f"Error parsing date {published_date}: {str(e)}")
                          return datetime.min
                  
                  # Sort by published date in descending order (newest first)
                  sorted_cpes = sorted(processed_products, key=extract_date_for_sorting, reverse=True)
                  
                  # Take the 5 most recent CPEs
                  recent_cpes = sorted_cpes[:5]
                  
                  # Print the selected CPEs for debugging
                  print("Selected CPEs by published date:")
                  for product in recent_cpes:
                      cpe_obj = product.get('cpe', {})
                      cpe_name = cpe_obj.get('cpeName', 'N/A')
                      published_date = cpe_obj.get('created', 'N/A')
                      print(f"  Name: {cpe_name}, Published: {published_date}")
                  
                  # Extract just the CPE names
                  cpe_names = [product.get('cpe', {}).get('cpeName') for product in recent_cpes
                              if product.get('cpe', {}).get('cpeName')]
                  
                  print(f"Using the {len(cpe_names)} most recent CPE names:")
                  for cpe_name in cpe_names:
                      print(f"  - {cpe_name}")
                  
                  return cpe_names
                  
              except Exception as e:
                  print(f"Error finding CPE names for {app_name}: {str(e)}")
                  import traceback
                  traceback.print_exc()
                  return []

          # Function to check CVEs for a specific CPE name
          def check_cves_for_cpe(cpe_name, app_name):
              print(f"\n{'-' * 50}")
              print(f"Checking CVEs for CPE: {cpe_name}")
              print(f"{'-' * 50}")
              
              # Get CVEs from the last 90 days
              end_date = datetime.now()
              start_date = end_date - timedelta(days=90)
              
              # Format dates for NVD API (ISO format)
              start_date_str = start_date.strftime("%Y-%m-%dT00:00:00.000")
              end_date_str = end_date.strftime("%Y-%m-%dT23:59:59.999")
              
              try:
                  # Query the NVD API for CVEs using the CPE name
                  # Construct the URL directly to ensure exact format
                  # cpe_name_encoded = quote(cpe_name)
                  start_date_encoded = quote(start_date_str)
                  url = f"https://services.nvd.nist.gov/rest/json/cves/2.0?cpeName={cpe_name}"
                  
                  # Set up headers with API key
                  headers = {'apiKey': nvd_api_key}
                  
                  # Make the request with API key in headers
                  response = requests.get(url, headers=headers)
                  
                  # Check if request was successful
                  if response.status_code != 200:
                      print(f"Error: CVE API request failed with status code {response.status_code}")
                      print(f"Response: {response.text}")
                      return []
                  
                  # Parse the JSON response
                  data = response.json()
                  
                  # Get the total count and vulnerabilities
                  total_results = data.get('totalResults', 0)
                  vulnerabilities = data.get('vulnerabilities', [])
                  
                  if total_results == 0 or not vulnerabilities:
                      print(f"No CVEs found for this CPE in the last 90 days.")
                      return []
                  
                  print(f"Found {total_results} CVEs for this CPE in the last 90 days.")
                  
                  # Process the vulnerabilities
                  processed_vulns = []
                  for vuln in vulnerabilities:
                      cve = vuln.get('cve', {})
                      
                      # Get CVE details
                      cve_id = cve.get('id', 'N/A')
                      
                      # Get description (English)
                      description = "N/A"
                      if 'descriptions' in cve:
                          for desc in cve['descriptions']:
                              if desc.get('lang') == 'en':
                                  description = desc.get('value', 'N/A')
                                  break
                      
                      # Get published and last modified dates
                      published_date = "N/A"
                      last_modified_date = "N/A"
                      published_datetime = None
                      last_modified_datetime = None
                      if 'published' in cve:
                          published_date = cve['published'].split('T')[0]
                          published_datetime = datetime.strptime(cve['published'].split('.')[0], "%Y-%m-%dT%H:%M:%S")
                      if 'lastModified' in cve:
                          last_modified_date = cve['lastModified'].split('T')[0]
                          last_modified_datetime = datetime.strptime(cve['lastModified'].split('.')[0], "%Y-%m-%dT%H:%M:%S")
                      
                      # Get CVSS score and severity if available
                      base_score = "N/A"
                      severity = "N/A"
                      
                      metrics = cve.get('metrics', {})
                      
                      # Try CVSS 3.1 first
                      if 'cvssMetricV31' in metrics and metrics['cvssMetricV31']:
                          cvss_data = metrics['cvssMetricV31'][0].get('cvssData', {})
                          base_score = cvss_data.get('baseScore', 'N/A')
                          severity = cvss_data.get('baseSeverity', 'N/A')
                      # Then try CVSS 3.0
                      elif 'cvssMetricV30' in metrics and metrics['cvssMetricV30']:
                          cvss_data = metrics['cvssMetricV30'][0].get('cvssData', {})
                          base_score = cvss_data.get('baseScore', 'N/A')
                          severity = cvss_data.get('baseSeverity', 'N/A')
                      # Finally try CVSS 2.0
                      elif 'cvssMetricV2' in metrics and metrics['cvssMetricV2']:
                          cvss_data = metrics['cvssMetricV2'][0].get('cvssData', {})
                          base_score = cvss_data.get('baseScore', 'N/A')
                          severity = metrics['cvssMetricV2'][0].get('baseSeverity', 'N/A')
                      
                      # Add to processed list with all details
                      processed_vulns.append({
                          'cve_id': cve_id,
                          'published_date': published_date,
                          'published_datetime': published_datetime,
                          'last_modified_date': last_modified_date,
                          'last_modified_datetime': last_modified_datetime,
                          'base_score': base_score,
                          'severity': severity,
                          'description': description,
                          'cpe_name': cpe_name
                      })
                  
                  return processed_vulns
                  
              except Exception as e:
                  print(f"Error checking CVEs for CPE {cpe_name}: {str(e)}")
                  import traceback
                  traceback.print_exc()
                  return []

          # Function to check CVEs for a specific app
          def check_cves_for_app(app_name, app_key):
              print(f"\n{'=' * 50}")
              print(f"Checking CVEs for {app_name}")
              print(f"{'=' * 50}")
              
              # Step 1: Get CPE names for the app
              cpe_names = get_cpe_names(app_name)
              
              if not cpe_names:
                  print(f"No CPE names found for {app_name}, cannot check for CVEs.")
                  return
              
              # Step 2: Get CVEs for each CPE name
              all_vulns = []
              for cpe_name in cpe_names:
                  vulns = check_cves_for_cpe(cpe_name, app_name)
                  all_vulns.extend(vulns)
                  
                  # Add a small delay between requests to avoid rate limiting
                  time.sleep(0.5)
              
              if not all_vulns:
                  print(f"No CVEs found for {app_name} in the last 90 days.")
                  return
              
              # Deduplicate CVEs by cve_id to avoid database constraint violations
              # Create a dictionary to store the most recent version of each CVE
              unique_cves = {}
              for vuln in all_vulns:
                  cve_id = vuln['cve_id']
                  # If we haven't seen this CVE before, or this one is more recent, keep it
                  if (cve_id not in unique_cves or
                      (vuln['published_datetime'] is not None and
                       unique_cves[cve_id]['published_datetime'] is not None and
                       vuln['published_datetime'] > unique_cves[cve_id]['published_datetime'])):
                      unique_cves[cve_id] = vuln
              
              # Convert back to a list
              deduplicated_vulns = list(unique_cves.values())
              
              # Sort by published date (newest first)
              sorted_vulns = sorted(
                  [v for v in deduplicated_vulns if v['published_datetime'] is not None],
                  key=lambda x: x['published_datetime'],
                  reverse=True
              )
              
              # Take only the 5 most recent CVEs
              recent_vulns = sorted_vulns[:5]
              
              print(f"\nFound {len(all_vulns)} total CVEs for {app_name} in the last 90 days.")
              print(f"Displaying the 5 most recent CVEs sorted by published date:")
              print(f"\n{'ID':<20} {'Published':<12} {'Last Modified':<12} {'Base Score':<10} {'Severity':<10}")
              print(f"{'-' * 72}")
              
              # First, delete existing CVEs for this app to avoid duplicates
              try:
                  print(f"Removing existing CVE records for {app_name}...")
                  supabase.table('app_cves').delete().eq('app_name', app_name).execute()
              except Exception as e:
                  print(f"Error deleting existing CVEs for {app_name}: {str(e)}")
              
              # Store the CVEs in the database
              if recent_vulns:
                  print(f"Storing {len(recent_vulns)} CVEs for {app_name} in the database...")
                  cve_records = []
                  for vuln in recent_vulns:
                      # Convert base_score to float if it's not N/A
                      base_score_value = None
                      if vuln['base_score'] != 'N/A':
                          try:
                              base_score_value = float(vuln['base_score'])
                          except:
                              pass
                          
                      cve_record = {
                          'app_name': app_name,
                          'cve_id': vuln['cve_id'],
                          'published_date': vuln['published_date'] if vuln['published_date'] != 'N/A' else None,
                          'last_modified_date': vuln['last_modified_date'] if vuln['last_modified_date'] != 'N/A' else None,
                          'base_score': base_score_value,
                          'severity': vuln['severity'] if vuln['severity'] != 'N/A' else None,
                          'description': vuln['description'] if vuln['description'] != 'N/A' else None,
                          'cpe_name': vuln['cpe_name']
                      }
                      cve_records.append(cve_record)
                  
                  try:
                      result = supabase.table('app_cves').insert(cve_records).execute()
                      print(f"✅ Successfully stored CVEs for {app_name} in the database")
                  except Exception as e:
                      print(f"Error storing CVEs for {app_name}: {str(e)}")
                  
                  # Create JSON file in CVE folder with the same name as in Apps/
                  try:
                      # Create a JSON structure for the CVE data
                      cve_json = {
                          "app_name": app_name,
                          "last_updated": datetime.now().strftime("%Y-%m-%d"),
                          "vulnerabilities": []
                      }
                      
                      for vuln in recent_vulns:
                          cve_json["vulnerabilities"].append({
                              "cve_id": vuln['cve_id'],
                              "published_date": vuln['published_date'],
                              "last_modified_date": vuln['last_modified_date'],
                              "base_score": vuln['base_score'],
                              "severity": vuln['severity'],
                              "description": vuln['description'],
                              "cpe_name": vuln['cpe_name']
                          })
                      
                      # Write to file with the same name as in Apps/
                      cve_file_path = cve_dir / f"{app_key}.json"
                      with open(cve_file_path, 'w') as f:
                          json.dump(cve_json, f, indent=2)
                      print(f"✅ Successfully created CVE file at {cve_file_path}")
                  except Exception as e:
                      print(f"Error creating CVE file for {app_name}: {str(e)}")
              
              # Display the results
              for vuln in recent_vulns:
                  print(f"{vuln['cve_id']:<20} {vuln['published_date']:<12} {vuln['last_modified_date']:<12} {vuln['base_score']:<10} {vuln['severity']:<10}")
                  print(f"CPE: {vuln['cpe_name']}")
                  print(f"Description: {vuln['description']}")
                  print(f"{'-' * 72}")
              
              # Show how many were found vs. how many are displayed
              if len(all_vulns) > 5:
                  print(f"Note: Showing 5 most recent CVEs out of {len(all_vulns)} found for {app_name}.")

          # Check CVEs for each app
          print(f"\nChecking CVEs for {len(apps_to_check)} apps:")
          for i, (app, app_key) in enumerate(zip(app_display_names, app_keys)):
              print(f"\n[{i+1}/{len(apps_to_check)}] Processing app: {app} (key: {app_key})")
              check_cves_for_app(app.strip(), app_key)
              # Add a larger delay between apps to avoid rate limiting
              # Since we're making multiple requests per app now
              time.sleep(2)  # 2 second delay between apps

          print("\nCVE check completed and data stored in Supabase database and CVE folder.")
          EOF

          python check_cves.py

      - name: Commit and push CVE files
        run: |
          # Check if there are any changes to commit
          if [[ -n $(git status --porcelain) ]]; then
            git config --global user.name 'GitHub Action'
            git config --global user.email 'action@github.com'
            git add CVE/
            git commit -m "Update CVE data [skip ci]"
            git push
          else
            echo "No changes to commit"
          fi
